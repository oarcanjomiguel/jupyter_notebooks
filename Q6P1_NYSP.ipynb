{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IA353 - Redes Neurais\n",
    "# EFC3 - Questão 6 - Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição de séries temporais empregando vários tipos de modelos\n",
    "#### Parcialmente baseado em https://github.com/ageron/handson-ml2/blob/master/15_processing_sequences_using_rnns_and_cnns.ipynb\n",
    "## Caso de estudo: Mercado de ações (NYSE: The New York Stock Exchange)\n",
    "#### Parcialmente baseado em https://www.kaggle.com/raoulma/ny-stock-price-prediction-rnn-lstm-gru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Professor:** Fernando J. Von Zuben <br>\n",
    "**Aluno(a):**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Importações e definições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import datetime\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Specifi imports\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    plt.plot(time[start:end], series[start:end], format)\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Time Series Values\")\n",
    "    plt.title(\"Sunspots Time Series\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Carregando a base de dados e apresentando sua composição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in 80%/10%/10% train/validation/test sets\n",
    "valid_set_size_percentage = 10 \n",
    "test_set_size_percentage = 10 \n",
    "\n",
    "# import all stock prices \n",
    "df = pd.read_csv(\"C:/IA353/prices-split-adjusted.csv\", index_col = 0)\n",
    "df.info()\n",
    "df.head()\n",
    "\n",
    "# number of different stocks\n",
    "print('\\nnumber of different stocks: ', len(list(set(df.symbol))))\n",
    "print(list(set(df.symbol))[:10])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Exibindo o comportamento temporal de várias séries associadas à ação EQIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5));\n",
    "plt.subplot(1,2,1);\n",
    "plt.plot(df[df.symbol == 'EQIX'].open.values, color='red', label='open')\n",
    "plt.plot(df[df.symbol == 'EQIX'].close.values, color='green', label='close')\n",
    "plt.plot(df[df.symbol == 'EQIX'].low.values, color='blue', label='low')\n",
    "plt.plot(df[df.symbol == 'EQIX'].high.values, color='black', label='high')\n",
    "plt.title('stock price')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('price')\n",
    "plt.legend(loc='best')\n",
    "#plt.show()\n",
    "\n",
    "plt.subplot(1,2,2);\n",
    "plt.plot(df[df.symbol == 'EQIX'].volume.values, color='black', label='volume')\n",
    "plt.title('stock volume')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('volume')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Escolha do preço de fechamento da ação EQIX e preparação da série temporal com linha de derivação de atraso, além de promover o particionamento entre conjuntos de treinamento, validação e teste\n",
    "#### Cabe comentar que os dados de teste não deveriam participar de nenhuma etapa de pré-processamento, pois, assim, têm o potencial de interferir no andamento do treinamento, desvirtuando o seu papel de apenas servirem para teste de desempenho. Cometeremos essa \"mancada\" metodológica para despertar o(a) aluno(a) para a questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for min-max normalization of stock\n",
    "def normalize_data(df):\n",
    "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
    "    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
    "    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
    "    df['close'] = min_max_scaler.fit_transform(df.close.values.reshape(-1,1))\n",
    "    return df\n",
    "\n",
    "# function to create train, validation, test data given stock data and sequence length\n",
    "def load_data(stock, seq_len):\n",
    "    data_raw = np.array(stock) # convert to numpy array\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - seq_len - 1): \n",
    "        data.append(data_raw[index: index + seq_len + 1])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    valid_set_size = int(np.round(valid_set_size_percentage/100*data.shape[0]));  \n",
    "    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (valid_set_size + test_set_size);\n",
    "    \n",
    "    # Choice of the close behavior\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,1]\n",
    "    y_train = data[:train_set_size,-1,1]\n",
    "    \n",
    "    x_valid = data[train_set_size:train_set_size+valid_set_size,:-1,1]\n",
    "    y_valid = data[train_set_size:train_set_size+valid_set_size,-1,1]\n",
    "    \n",
    "    x_test = data[train_set_size+valid_set_size:,:-1,1]\n",
    "    y_test = data[train_set_size+valid_set_size:,-1,1]\n",
    "    \n",
    "    x_train = np.asarray(x_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_train = y_train.reshape(-1,1)\n",
    "    x_valid = np.asarray(x_valid)\n",
    "    y_valid = np.asarray(y_valid)\n",
    "    y_valid = y_valid.reshape(-1,1)\n",
    "    x_test = np.asarray(x_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "    y_test = y_test.reshape(-1,1)\n",
    "    \n",
    "    np.savetxt('Q6P1_x_train.txt', x_train)\n",
    "    np.savetxt('Q6P1_y_train.txt', y_train)\n",
    "    np.savetxt('Q6P1_x_valid.txt', x_valid)\n",
    "    np.savetxt('Q6P1_y_valid.txt', y_valid)\n",
    "    np.savetxt('Q6P1_x_test.txt', x_test)\n",
    "    np.savetxt('Q6P1_y_test.txt', y_test)\n",
    "\n",
    "    return [x_train, y_train, x_valid, y_valid, x_test, y_test]\n",
    "\n",
    "# choose one stock\n",
    "print('Chosen stock is EQIX')\n",
    "df_stock = df[df.symbol == 'EQIX'].copy()\n",
    "df_stock.drop(['symbol'],1,inplace=True)\n",
    "df_stock.drop(['volume'],1,inplace=True)\n",
    "\n",
    "cols = list(df_stock.columns.values)\n",
    "print('df_stock.columns.values = ', cols[1])\n",
    "\n",
    "# normalize stock\n",
    "df_stock_norm = df_stock.copy()\n",
    "df_stock_norm = normalize_data(df_stock_norm)\n",
    "\n",
    "# create train, test data\n",
    "seq_len = 20 # choose sequence length\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(df_stock_norm, seq_len)\n",
    "print('x_train.shape = ',x_train.shape)\n",
    "print('y_train.shape = ', y_train.shape)\n",
    "print('x_valid.shape = ',x_valid.shape)\n",
    "print('y_valid.shape = ', y_valid.shape)\n",
    "print('x_test.shape = ', x_test.shape)\n",
    "print('y_test.shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5. Visualização do comportamento da série temporal normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5));\n",
    "plt.plot(df_stock_norm.close.values, color='green', label='close')\n",
    "plt.title('stock')\n",
    "plt.xlabel('time [days]')\n",
    "plt.ylabel('normalized price')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6. Sintetizando um preditor linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "nr,nc = x_train.shape\n",
    "B = np.ones((nr,1))\n",
    "X = np.hstack((x_train,B))\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y_train)\n",
    "w = lr.coef_[0]\n",
    "print('Coeficientes do preditor linear')\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6.1. Visualização do desempenho do preditor linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('EQM final de treinamento após o término do treinamento - Preditor Linear')\n",
    "nr,nc = x_train.shape\n",
    "B = np.ones((nr,1))\n",
    "X = np.hstack((x_train,B))\n",
    "y_pred = X.dot(w)\n",
    "MSE_train = mean_squared_error(y_train,y_pred)\n",
    "print(MSE_train)\n",
    "print('EQM final de validação após o término do treinamento - Preditor Linear')\n",
    "nr,nc = x_valid.shape\n",
    "B = np.ones((nr,1))\n",
    "X = np.hstack((x_valid,B))\n",
    "y_pred = X.dot(w)\n",
    "MSE_valid = mean_squared_error(y_valid,y_pred)\n",
    "print(MSE_valid)\n",
    "print('EQM final de teste após o término do treinamento - Preditor Linear')\n",
    "nr,nc = x_test.shape\n",
    "B = np.ones((nr,1))\n",
    "X = np.hstack((x_test,B))\n",
    "y_pred = X.dot(w)\n",
    "MSE_test = mean_squared_error(y_test,y_pred)\n",
    "print(MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = X.dot(w)\n",
    "plt.figure(figsize=(15, 5));\n",
    "plt.plot(y_test, color='red', label='Valor esperado')\n",
    "plt.plot(y_pred, color='blue', label='Valor predito')\n",
    "plt.title('Desempenho do preditor linear junto aos dados de teste')\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Stock price')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7. Sintetizando um preditor não-linear MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_MLP = keras.models.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(64, activation=tf.nn.tanh),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_MLP.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=EPOCHS) # Se desejar early stopping, definir patience = 10\n",
    "best_val = ModelCheckpoint('model_MLP_{epoch:02d}.h5', save_best_only=True, mode='min', period=1)\n",
    "history = model_MLP.fit(x_train, y_train, \n",
    "                        epochs=EPOCHS, \n",
    "                        validation_data=(x_valid, y_valid), \n",
    "                        callbacks=[earlystop, best_val], \n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MLP.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.1. Carregando o modelo com o menor MAPE para o preditor MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(np.array(history.history['val_loss']))+1\n",
    "model_MLP.load_weights(\"model_MLP_{:02d}.h5\".format(best_epoch))\n",
    "plot_df = pd.DataFrame.from_dict({'train_loss':history.history['loss'], 'val_loss':history.history['val_loss']})\n",
    "plot_df.plot(logy=True, figsize=(15,5), fontsize=12)\n",
    "plt.xlabel('epoch', fontsize=12)\n",
    "plt.ylabel('loss', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.2. Visualização do desempenho do preditor MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#weights = model_MLP.get_weights()\n",
    "#print(weights)\n",
    "print('EQM final de treinamento após o término do treinamento - Preditor MLP')\n",
    "y_pred = model_MLP.predict(x_train)\n",
    "MSE_train = mean_squared_error(y_train,y_pred)\n",
    "print(MSE_train)\n",
    "print('EQM final de validação após o término do treinamento - Preditor MLP')\n",
    "y_pred = model_MLP.predict(x_valid)\n",
    "MSE_valid = mean_squared_error(y_valid,y_pred)\n",
    "print(MSE_valid)\n",
    "print('EQM final de teste após o término do treinamento - Preditor MLP')\n",
    "y_pred = model_MLP.predict(x_test)\n",
    "MSE_test = mean_squared_error(y_test,y_pred)\n",
    "print(MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_MLP.predict(x_test)\n",
    "plt.figure(figsize=(15, 5));\n",
    "plt.plot(y_test, color='red', label='Valor esperado')\n",
    "plt.plot(y_pred, color='blue', label='Valor predito')\n",
    "plt.title('Desempenho do preditor MLP junto aos dados de teste')\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Stock price')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8. Sintetizando um preditor não-linear Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "if len(x_train.shape) < 3:\n",
    "    x_train = np.expand_dims(x_train, axis=2)\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "x_valid = np.asarray(x_valid)\n",
    "if len(x_valid.shape) < 3:\n",
    "    x_valid = np.expand_dims(x_valid, axis=2)\n",
    "y_valid = np.asarray(y_valid)\n",
    "y_valid = y_valid.reshape(-1,1)\n",
    "x_test = np.asarray(x_test)\n",
    "if len(x_test.shape) < 3:\n",
    "    x_test = np.expand_dims(x_test, axis=2)\n",
    "y_test = np.asarray(y_test)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_RNN1 = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_RNN1.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=EPOCHS) # Se desejar early stopping, definir patience = 10\n",
    "best_val = ModelCheckpoint('model_RNN1_{epoch:02d}.h5', save_best_only=True, mode='min', period=1)\n",
    "history = model_RNN1.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=[earlystop, best_val],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.8.1. Carregando o modelo com o menor MAPE para o preditor não-linear Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(np.array(history.history['val_loss']))+1\n",
    "model_RNN1.load_weights(\"model_RNN1_{:02d}.h5\".format(best_epoch))\n",
    "plot_df = pd.DataFrame.from_dict({'train_loss':history.history['loss'], 'val_loss':history.history['val_loss']})\n",
    "plot_df.plot(logy=True, figsize=(15,5), fontsize=12)\n",
    "plt.xlabel('epoch', fontsize=12)\n",
    "plt.ylabel('loss', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.8.2. Visualização do desempenho do preditor não-linear Simple RNN junto aos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EQM final de treinamento após o término do treinamento - Preditor Simple RNN')\n",
    "y_pred = model_RNN1.predict(x_train)\n",
    "MSE_train = mean_squared_error(y_train,y_pred)\n",
    "print(MSE_train)\n",
    "print('EQM final de validação após o término do treinamento - Preditor Simple RNN')\n",
    "y_pred = model_RNN1.predict(x_valid)\n",
    "MSE_valid = mean_squared_error(y_valid,y_pred)\n",
    "print(MSE_valid)\n",
    "print('EQM final de teste após o término do treinamento - Preditor Simple RNN')\n",
    "y_pred = model_RNN1.predict(x_test)\n",
    "MSE_test = mean_squared_error(y_test,y_pred)\n",
    "print(MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_RNN1.predict(x_test)\n",
    "plt.figure(figsize=(15, 5));\n",
    "plt.plot(y_test, color='red', label='Valor esperado')\n",
    "plt.plot(y_pred, color='blue', label='Valor predito')\n",
    "plt.title('Desempenho do preditor Simple RNN junto aos dados de teste')\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Stock price')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9. Sintetizando um preditor não-linear com bloco LSTM GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "if len(x_train.shape) < 3:\n",
    "    x_train = np.expand_dims(x_train, axis=2)\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "x_valid = np.asarray(x_valid)\n",
    "if len(x_valid.shape) < 3:\n",
    "    x_valid = np.expand_dims(x_valid, axis=2)\n",
    "y_valid = np.asarray(y_valid)\n",
    "y_valid = y_valid.reshape(-1,1)\n",
    "x_test = np.asarray(x_test)\n",
    "if len(x_test.shape) < 3:\n",
    "    x_test = np.expand_dims(x_test, axis=2)\n",
    "y_test = np.asarray(y_test)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_RNN2 = keras.models.Sequential([\n",
    "    keras.layers.GRU(seq_len, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.GRU(seq_len, return_sequences=True),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_RNN2.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=EPOCHS) # Se desejar early stopping, definir patience = 10\n",
    "best_val = ModelCheckpoint('model_RNN2_{epoch:02d}.h5', save_best_only=True, mode='min', period=1)\n",
    "history = model_RNN2.fit(x_train,\n",
    "          y_train,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=[earlystop, best_val],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_RNN2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.9.1. Carregando o modelo com o menor MAPE para o preditor não-linear com bloco LSTM GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(np.array(history.history['val_loss']))+1\n",
    "model_RNN2.load_weights(\"model_RNN2_{:02d}.h5\".format(best_epoch))\n",
    "plot_df = pd.DataFrame.from_dict({'train_loss':history.history['loss'], 'val_loss':history.history['val_loss']})\n",
    "plot_df.plot(logy=True, figsize=(15,5), fontsize=12)\n",
    "plt.xlabel('epoch', fontsize=12)\n",
    "plt.ylabel('loss', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.9.2. Visualização do desempenho do preditor não-linear com bloco LSTM GRU junto aos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EQM final de treinamento após o término do treinamento - Preditor LSTM GRU')\n",
    "model_RNN2.evaluate(x_train,y_train)\n",
    "print('EQM final de validação após o término do treinamento - Preditor LSTM GRU')\n",
    "model_RNN2.evaluate(x_valid,y_valid)\n",
    "print('EQM final de teste após o término do treinamento - Preditor LSTM GRU')\n",
    "model_RNN2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_RNN2.predict(x_test)\n",
    "plt.figure(figsize=(15, 5));\n",
    "plt.plot(y_test, color='red', label='Valor esperado')\n",
    "plt.plot(y_pred[:,seq_len - 1], color='blue', label='Valor predito')\n",
    "plt.title('Desempenho do preditor LSTM GRU junto aos dados de teste')\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Stock price')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.10. Sintetizando um preditor não-linear CNN 1D\n",
    "#### Parcialmente baseado em https://github.com/Azure/DeepLearningForTimeSeriesForecasting/blob/master/1_CNN_dilated.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Dense, Flatten\n",
    "LATENT_DIM = 5\n",
    "KERNEL_SIZE = 2\n",
    "BATCH_SIZE = 32\n",
    "model_CNN = Sequential()\n",
    "model_CNN.add(Conv1D(LATENT_DIM, kernel_size=KERNEL_SIZE, padding='causal', strides=1, activation='relu', dilation_rate=1, input_shape=(seq_len, 1)))\n",
    "model_CNN.add(Conv1D(LATENT_DIM, kernel_size=KERNEL_SIZE, padding='causal', strides=1, activation='relu', dilation_rate=2))\n",
    "model_CNN.add(Conv1D(LATENT_DIM, kernel_size=KERNEL_SIZE, padding='causal', strides=1, activation='relu', dilation_rate=4))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dense(1, activation='linear'))\n",
    "model_CNN.compile(optimizer='Adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=EPOCHS) # Se desejar early stopping, definir patience = 10\n",
    "best_val = ModelCheckpoint('model_CNN_{epoch:02d}.h5', save_best_only=True, mode='min', period=1)\n",
    "history = model_CNN.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=[earlystop, best_val],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.10.1. Carregando o modelo com o menor MAPE para o preditor CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(np.array(history.history['val_loss']))+1\n",
    "model_CNN.load_weights(\"model_CNN_{:02d}.h5\".format(best_epoch))\n",
    "plot_df = pd.DataFrame.from_dict({'train_loss':history.history['loss'], 'val_loss':history.history['val_loss']})\n",
    "plot_df.plot(logy=True, figsize=(15,5), fontsize=12)\n",
    "plt.xlabel('epoch', fontsize=12)\n",
    "plt.ylabel('loss', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.10.2. Visualização do desempenho do preditor CNN junto aos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EQM final de treinamento após o término do treinamento - Preditor CNN')\n",
    "y_pred = model_CNN.predict(x_train)\n",
    "MSE_train = mean_squared_error(y_train,y_pred)\n",
    "print(MSE_train)\n",
    "print('EQM final de validação após o término do treinamento - Preditor CNN')\n",
    "y_pred = model_CNN.predict(x_valid)\n",
    "MSE_valid = mean_squared_error(y_valid,y_pred)\n",
    "print(MSE_valid)\n",
    "print('EQM final de teste após o término do treinamento - Preditor CNN')\n",
    "y_pred = model_CNN.predict(x_test)\n",
    "MSE_test = mean_squared_error(y_test,y_pred)\n",
    "print(MSE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_CNN.predict(x_test)\n",
    "plt.figure(figsize=(15, 5));\n",
    "plt.plot(y_test, color='red', label='Valor esperado')\n",
    "plt.plot(y_pred, color='blue', label='Valor predito')\n",
    "plt.title('Desempenho do preditor CNN junto aos dados de teste')\n",
    "plt.xlabel('Time steps')\n",
    "plt.ylabel('Stock price')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
